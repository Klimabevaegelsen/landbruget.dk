from typing import Dict, List
import xml.etree.ElementTree as ET
import requests
import logging

if 'data_loader' not in globals():
    from mage_ai.data_preparation.decorators import data_loader
if 'test' not in globals():
    from mage_ai.data_preparation.decorators import test

logger = logging.getLogger(__name__)

@data_loader
def load_data(data: Dict = None, *args, **kwargs) -> Dict:
    """
    Fetches raw data for a single chunk of wetlands features.
    This loader is designed to run in parallel for each chunk.
    
    Args:
        data: In dynamic execution, this will be a dictionary containing the chunk information
            directly (start_index, end_index, size)
            
    Returns:
        Dictionary containing:
            - features: List of raw feature data
            - chunk_info: Information about the processed chunk
    """
    if data is None:
        raise ValueError("No data received")
        
    # In dynamic execution, the data is the chunk information directly
    chunk = {
        'start_index': data.get('start_index'),
        'end_index': data.get('end_index'),
        'size': data.get('size')
    }
    
    # Get metadata from the upstream block's output
    if 'upstream_data_loader' in kwargs:
        metadata = kwargs['upstream_data_loader'].get('metadata', {})
    else:
        # Fallback configuration if metadata is not available
        metadata = {
            'url': 'https://wfs2-miljoegis.mim.dk/natur/wfs',
            'layer': 'natur:kulstof2022',
            'timeout': 300
        }
    
    logger.info(f"Fetching chunk: {chunk['start_index']} to {chunk['end_index']}")
    
    # WFS parameters for this chunk
    params = {
        'SERVICE': 'WFS',
        'REQUEST': 'GetFeature',
        'VERSION': '2.0.0',
        'TYPENAMES': metadata.get('layer', 'natur:kulstof2022'),
        'SRSNAME': 'EPSG:25832',
        'count': str(chunk['size']),
        'startIndex': str(chunk['start_index'])
    }
    
    # Define namespaces for XML parsing
    namespaces = {
        'wfs': 'http://www.opengis.net/wfs/2.0',
        'natur': 'http://wfs2-miljoegis.mim.dk/natur',
        'gml': 'http://www.opengis.net/gml/3.2'
    }
    
    try:
        # Fetch the chunk data
        response = requests.get(
            metadata.get('url', 'https://wfs2-miljoegis.mim.dk/natur/wfs'),
            params=params, 
            timeout=metadata.get('timeout', 300)
        )
        response.raise_for_status()
        
        root = ET.fromstring(response.text)
        
        # Extract raw feature data
        features = []
        for feature in root.findall('.//natur:kulstof2022', namespaces):
            try:
                # Get geometry as raw coordinates
                geom_elem = feature.find('.//gml:Polygon', namespaces)
                if geom_elem is None:
                    continue
                    
                coords_elem = geom_elem.find('.//gml:posList', namespaces)
                if coords_elem is None or not coords_elem.text:
                    continue
                
                # Extract raw feature data
                feature_data = {
                    'id': feature.get('{http://www.opengis.net/gml/3.2}id'),
                    'gridcode': feature.find('natur:gridcode', namespaces).text,
                    'toerv_pct': feature.find('natur:toerv_pct', namespaces).text,
                    'coordinates': coords_elem.text  # Keep raw coordinate string
                }
                
                features.append(feature_data)
                
            except Exception as e:
                logger.warning(f"Error extracting feature data: {str(e)}")
                continue
        
        return {
            'chunk_info': chunk,
            'feature_count': len(features),
            'features': features,
            'crs': "EPSG:25832"
        }
        
    except requests.exceptions.RequestException as e:
        logger.error(f"Error fetching chunk {chunk['start_index']}-{chunk['end_index']}: {str(e)}")
        raise
    except Exception as e:
        logger.error(f"Error processing chunk {chunk['start_index']}-{chunk['end_index']}: {str(e)}")
        raise

@test
def test_output(output: Dict) -> None:
    """
    Test the output of the data loader.
    """
    assert isinstance(output, dict), 'Output must be a dictionary'
    assert 'chunk_info' in output, 'Output must contain chunk_info'
    assert 'feature_count' in output, 'Output must contain feature_count'
    assert 'features' in output, 'Output must contain features'
    assert 'crs' in output, 'Output must contain crs'
    
    # Validate chunk info
    chunk_info = output['chunk_info']
    assert 'start_index' in chunk_info, 'Chunk info must contain start_index'
    assert 'end_index' in chunk_info, 'Chunk info must contain end_index'
    assert 'size' in chunk_info, 'Chunk info must contain size'
    
    # Validate features
    assert isinstance(output['features'], list), 'Features must be a list'
    if output['features']:
        feature = output['features'][0]
        assert 'id' in feature, 'Feature must contain id'
        assert 'gridcode' in feature, 'Feature must contain gridcode'
        assert 'toerv_pct' in feature, 'Feature must contain toerv_pct'
        assert 'coordinates' in feature, 'Feature must contain coordinates'